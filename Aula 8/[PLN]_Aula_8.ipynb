{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Aula 08 - Introdução a Machine Learning para PLN**\n",
        "\n",
        "**Aluna:** Giovanna da Rocha Machado | **RA:** 1131392213024\n",
        "\n",
        "Nesta aula, exploramos conceitos básicos de Machine Learning aplicado ao Processamento de Linguagem Natural (PLN).\n",
        "Abordaremos classificação de sentimentos com vetorização de texto com TF-IDF, modelos de aprendizado supervisionado.\n",
        "\n",
        "A aula inclui dois exemplos práticos:\n",
        "\n",
        "- Um estudo com um corpus simples de frases em português para treinar e avaliar um modelo SVM.\n",
        "- Um exemplo mais avançado com o dataset com análises de filmes do NLTK, onde compararemos o desempenho dos modelos Naive Bayes e SVM em uma tarefa de classificação binária."
      ],
      "metadata": {
        "id": "2G3chbMQgCNZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exemplo 01**: Aplicação do modelo de Naives em um texto"
      ],
      "metadata": {
        "id": "agGFW6aXn9Rd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1 - Criar o Corpus\n",
        "\n",
        "corpus = [\n",
        "    (\"Eu amo PLN\", \"positivo\"),\n",
        "    (\"Eu odeio bugs\", \"negativo\"),\n",
        "    (\"Amo resolver problemas\", \"positivo\"),\n",
        "    (\"Odeio erros\", \"negativo\"),\n",
        "    (\"Bugs são legais\", \"positivo\"),\n",
        "    (\"Resolver dificuldades é vida\", \"positivo\"),\n",
        "    (\"Eu não gosto de falhas\", \"negativo\"),\n",
        "]\n",
        "\n",
        "# Passo 2 - Processar o Texto\n",
        "import re # Lib para trabalhar com expressões regulares\n",
        "from collections import defaultdict, Counter # Contagem e estruturação de dados\n",
        "\n",
        "def preprocess_text(text):\n",
        "  return re.findall(r'\\b\\w+\\b', text.lower())\n",
        "\n",
        "# Converte o texto para minúsculas e divide em tokens utilizando expressões regulares.\n",
        "processed_corpus = [(preprocess_text(text), label) for text, label in corpus]\n",
        "print(processed_corpus)\n",
        "\n",
        "# Passo 3 - Calculando probabilidades\n",
        "class_counts = Counter() # Contador para armazenar a quantidade de exemplos em cada classe\n",
        "word_counts = defaultdict(Counter)  # Armazenar a contagem de palavras em cada classe\n",
        "total_words = defaultdict(int) # Armazenar o total de palavras em cada classe\n",
        "\n",
        "# Itera sobre o corpus pré-processado para calcular as contagens\n",
        "for words, label in processed_corpus:\n",
        "  class_counts[label] += 1 # Incrementa a contagem de exemplos para a classe\n",
        "  for word in words:\n",
        "    word_counts[label][word] += 1  # Incrementa a contagem da palavra na classe\n",
        "    total_words[label]\n",
        "\n",
        "# Nº total de exemplos no corpus\n",
        "total_examples = sum(class_counts.values())\n",
        "\n",
        "# Calculando as probabilidades a priori (P(classe)) para cada classe\n",
        "prior_probabilities = {cls: count / total_examples for cls, count in class_counts.items()}\n",
        "\n",
        "# Função para calcular a probabilidade condicional P(palavra|classe) com suavização de Laplace (alpha)\n",
        "def conditional_probability(word, label, alpha=1):\n",
        "  # Fórmula: (contagem da palavra + alpha) / (total de palavras na classe + alpha * tamanho do vocabulário)\n",
        "  return (word_counts[label][word] + alpha) / (total_words[label] + alpha * len(word_counts[label]))\n",
        "\n",
        "# Passo 4 - Classificar um novo texto\n",
        "def predict(text):\n",
        "  words = preprocess_text(text) # Pré-processa o texto de entrada (tokenização)\n",
        "  probabilities = {} # Armazenar as probabilidades para cada classe\n",
        "\n",
        "  # Calculando as probabilidades para cada classe\n",
        "  for label in class_counts.keys():\n",
        "    probabilities[label] = prior_probabilities[label]  # Inicializa com a probabilidade a priori da classe\n",
        "    for word in words:\n",
        "      probabilities[label] *= conditional_probability(word, label) # Multiplica pela probabilidade condicional\n",
        "  return max(probabilities, key=probabilities.get), probabilities # Retorna a classe com maior probabilidade\n",
        "\n",
        "# Passo 5 - Teste com um novo texto\n",
        "novo_texto = \"Eu amo resolver bugs\"\n",
        "\n",
        "# Previsão utilizando a função predict\n",
        "classe, probs = predict(novo_texto)\n",
        "\n",
        "print(f'Texto: \"{novo_texto}\"')\n",
        "print(f'Classe prevista: \"{classe}\"')\n",
        "print(f'Probabilidades:')\n",
        "for label, prob in probs.items():\n",
        "  print(f'{label}\"{prob}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pWc6GJdoDGj",
        "outputId": "29ca406c-5323-4ddf-f858-473555e4689b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['eu', 'amo', 'pln'], 'positivo'), (['eu', 'odeio', 'bugs'], 'negativo'), (['amo', 'resolver', 'problemas'], 'positivo'), (['odeio', 'erros'], 'negativo'), (['bugs', 'são', 'legais'], 'positivo'), (['resolver', 'dificuldades', 'é', 'vida'], 'positivo'), (['eu', 'não', 'gosto', 'de', 'falhas'], 'negativo')]\n",
            "Texto: \"Eu amo resolver bugs\"\n",
            "Classe prevista: \"positivo\"\n",
            "Probabilidades:\n",
            "positivo\"0.0014050562510367166\"\n",
            "negativo\"0.0006277901785714285\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exemplo 2**: Classificação de Sentimentos com SVM e TF-IDF"
      ],
      "metadata": {
        "id": "6W3kr-ungtzY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2a7P8gar9SC",
        "outputId": "16600624-036a-41e6-8d04-fdaa609ff9ed"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Passo 1: Importação das bibliotecas necessárias\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Para representar texto com TF-IDF\n",
        "from sklearn.svm import SVC  # Para o modelo de máquina de vetores de suporte (SVM)\n",
        "from sklearn.model_selection import train_test_split  # Para dividir os dados em treino e teste\n",
        "from sklearn.metrics import classification_report  # Para avaliar a performance do modelo\n",
        "\n",
        "# Passo 2: Definição do corpus e classes\n",
        "corpus = [\n",
        "    \"Eu amo PLN\",\n",
        "    \"Eu odeio bugs\",\n",
        "    \"Eu amo resolver problemas\",\n",
        "    \"Odeio erros\",\n",
        "    \"Amo programação\",\n",
        "    \"Não gosto de falhas\"\n",
        "]\n",
        "classes = [\"positivo\", \"negativo\", \"positivo\", \"negativo\", \"positivo\", \"negativo\"] # Cada texto no corpus possui uma classe associada\n",
        "\n",
        "# Passo 3: Pré-processamento e vetorização com TF-IDF\n",
        "vectorizer = TfidfVectorizer()  # Instancia o vetor TF-IDF\n",
        "X = vectorizer.fit_transform(corpus)  # Ajusta e transforma o corpus em uma matriz numérica\n",
        "y = classes  # As classes alvo\n",
        "\n",
        "# Passo 4: Divisão dos dados em treino e teste\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "# test_size=0.3 significa que 30% dos dados serão usados para teste\n",
        "# random_state=42 garante reprodutibilidade\n",
        "\n",
        "# Treinamento do modelo SVM\n",
        "svm_model = SVC(kernel='linear')  # Cria um modelo SVM com kernel linear\n",
        "svm_model.fit(X_train, y_train)  # Treinar o modelo com os dados de treino\n",
        "\n",
        "# Passo 5: Avaliação do modelo\n",
        "y_pred = svm_model.predict(X_test)  # Faz predições no conjunto de teste\n",
        "print(classification_report(y_test, y_pred))  # Exibe métricas de desempenho\n"
      ],
      "metadata": {
        "id": "TgUMqT8_gZKp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c69d7ab3-9bd7-4945-cd8c-387d1bde2550"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negativo       1.00      1.00      1.00         1\n",
            "    positivo       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exemplo 3**: Classificação de Sentimentos em Inglês com TF-IDF, Naive Bayes e SVM"
      ],
      "metadata": {
        "id": "RTo_ods0iCC_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Importação das bibliotecas necessárias\n",
        "import nltk  # Biblioteca para processamento de linguagem natural\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer  # Vetorização com TF-IDF\n",
        "from sklearn.model_selection import train_test_split  # Divisão dos dados em conjuntos de treino e teste\n",
        "from sklearn.naive_bayes import MultinomialNB  # Modelo de classificação baseado no Naive Bayes\n",
        "from sklearn.svm import SVC  # SVM\n",
        "from sklearn.metrics import classification_report  # Métricas de avaliação como precisão, recall e F1-score\n",
        "from sklearn.preprocessing import LabelEncoder  # Codificação de labels em valores numéricos\n",
        "\n",
        "# Baixar o dataset de exemplo\n",
        "nltk.download('movie_reviews')  # Baixa o corpus de análises de filmes\n",
        "from nltk.corpus import movie_reviews  # Importando corpus pós download\n",
        "\n",
        "# 2. Preparação dos dados\n",
        "# Coleta os textos e suas classes (positiva / negativa)\n",
        "documents = [\n",
        "    (\" \".join(movie_reviews.words(fileid)), category)  # Junta palavras de cada análise em uma string\n",
        "    for category in movie_reviews.categories()  # Itera sobre categorias 'pos' e 'neg'\n",
        "    for fileid in movie_reviews.fileids(category)  # Itera nos IDs de arquivo para cada categoria\n",
        "]\n",
        "# O corpus resulta em uma lista de tuplas (texto, classe)\n",
        "\n",
        "# Separar textos e rótulos em variáveis separadas\n",
        "texts, labels = zip(*documents)  # 'texts' contém análises, 'labels' contém classes\n",
        "\n",
        "# Transformar rótulos em valores numéricos (0 = 'neg', 1 = 'pos')\n",
        "label_encoder = LabelEncoder()  # Codificador de rótulos\n",
        "labels = label_encoder.fit_transform(labels)  # Converte classes string para números\n",
        "\n",
        "# Divide os dados em conjuntos de treino e teste\n",
        "texts_train, texts_test, labels_train, labels_test = train_test_split(\n",
        "    texts,  # Textos\n",
        "    labels,  # Classes\n",
        "    test_size=0.3,  # 30% dos dados para o conjunto de teste\n",
        "    random_state=42  # Semente aleatória\n",
        ")\n",
        "\n",
        "# 3. Representação do texto com TF-IDF\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # max_features: Limita o vocabulário às x palavras mais frequentes\n",
        "X_train = vectorizer.fit_transform(texts_train)  # Ajusta o vetorizador TF-IDF aos textos de treino e transforma em vetores numéricos\n",
        "X_test = vectorizer.transform(texts_test)  # Transforma os textos teste em vetores numéricos usando o modelo ajustado no treino\n",
        "\n",
        "# 4. Treinamento dos modelos\n",
        "\n",
        "# Treinamento do Naive Bayes\n",
        "nb_model = MultinomialNB()  # Modelo Naive Bayes Multinomial, adequado para dados de contagem (como TF-IDF)\n",
        "nb_model.fit(X_train, labels_train)  # Treina o modelo com os vetores TF-IDF de treino e rótulos\n",
        "\n",
        "# Predição com Naive Bayes\n",
        "nb_predictions = nb_model.predict(X_test)  # Usa o modelo treinado para prever classes dos textos de teste\n",
        "\n",
        "# Treinamento do SVM\n",
        "svm_model = SVC(kernel='linear')\n",
        " # SVC: Modelo de Máquina de Vetores de Suporte\n",
        "# kernel='linear': Utiliza kernel linear para encontrar hiperplanos que separam as classes\n",
        "\n",
        "svm_model.fit(X_train, labels_train)  # Treina o modelo SVM com os vetores TF-IDF de treino e rótulos\n",
        "\n",
        "# Predição com SVM\n",
        "svm_predictions = svm_model.predict(X_test)  # Usa o modelo treinado para prever as classes dos textos de teste\n",
        "\n",
        "# 5. Avaliação dos modelos\n",
        "\n",
        "# Avaliação do Naive Bayes\n",
        "print(\"Desempenho do Naive Bayes:\")\n",
        "print(classification_report(labels_test, nb_predictions, target_names=label_encoder.classes_))\n",
        "# classification_report: Métricas como precisão, recall, F1-score...\n",
        "# labels_test: Rótulos reais\n",
        "# nb_predictions: Rótulos previstos pelo modelo Naive Bayes\n",
        "# target_names: Nomes originais classes ('neg', 'pos')\n",
        "\n",
        "# Avaliação do SVM\n",
        "print(\"Desempenho do SVM:\")\n",
        "print(classification_report(labels_test, svm_predictions, target_names=label_encoder.classes_))\n",
        "# labels_test: Rótulos reais\n",
        "# svm_predictions: Rótulos previstos pelo modelo SVM\n",
        "# target_names: Nomes originais classes ('neg', 'pos')\n"
      ],
      "metadata": {
        "id": "8JqLyQuTiIh3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5c015e-f000-4f8e-e50b-157147bd9642"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Desempenho do Naive Bayes:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.79      0.84      0.81       302\n",
            "         pos       0.82      0.77      0.80       298\n",
            "\n",
            "    accuracy                           0.80       600\n",
            "   macro avg       0.80      0.80      0.80       600\n",
            "weighted avg       0.80      0.80      0.80       600\n",
            "\n",
            "Desempenho do SVM:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         neg       0.82      0.80      0.81       302\n",
            "         pos       0.81      0.82      0.81       298\n",
            "\n",
            "    accuracy                           0.81       600\n",
            "   macro avg       0.81      0.81      0.81       600\n",
            "weighted avg       0.81      0.81      0.81       600\n",
            "\n"
          ]
        }
      ]
    }
  ]
}